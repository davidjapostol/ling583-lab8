{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "critical-scotland",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "optical-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cytoolz import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "british-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('s3://ling583/sentiment.parquet', storage_options={'anon': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "studied-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = DocBin().from_disk('parsed.docbin')\n",
    "df['doc'] = list(docs.get_docs(nlp.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "parental-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "warming-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(df,\n",
    "                             test_size=0.2,\n",
    "                             stratify=df['sentiment'],\n",
    "                             random_state=619)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-warrior",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "conscious-owner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"8eee4c0f84a24f5b8ed24c4aa6d69072-0\" class=\"displacy\" width=\"1275\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">They</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">did</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">n't</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">have</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">any</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">clean</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">towels.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8eee4c0f84a24f5b8ed24c4aa6d69072-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 575.0,2.0 575.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8eee4c0f84a24f5b8ed24c4aa6d69072-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8eee4c0f84a24f5b8ed24c4aa6d69072-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8eee4c0f84a24f5b8ed24c4aa6d69072-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8eee4c0f84a24f5b8ed24c4aa6d69072-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8eee4c0f84a24f5b8ed24c4aa6d69072-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8eee4c0f84a24f5b8ed24c4aa6d69072-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8eee4c0f84a24f5b8ed24c4aa6d69072-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8eee4c0f84a24f5b8ed24c4aa6d69072-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8eee4c0f84a24f5b8ed24c4aa6d69072-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8eee4c0f84a24f5b8ed24c4aa6d69072-0-5\" stroke-width=\"2px\" d=\"M595,264.5 C595,2.0 1100.0,2.0 1100.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8eee4c0f84a24f5b8ed24c4aa6d69072-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,266.5 L1108.0,254.5 1092.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(\"They didn't have any clean towels.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "junior-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Token\n",
    "Token.set_extension('neg', default=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "complimentary-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in df['doc']:\n",
    "    for t in doc:\n",
    "        if t.dep_ == 'neg':\n",
    "            t.head._.neg = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bearing-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_neg(token):\n",
    "    return 'NOT:'+token.norm_ if token._.neg else token.norm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dying-palestine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    return [add_neg(t) for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "passing-drilling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8989"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = make_pipeline(CountVectorizer(preprocessor=identity, tokenizer=tokenize),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-5))\n",
    "m1.fit(train['doc'], train['sentiment'])\n",
    "m1.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "continued-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_feats(M, k=0):\n",
    "    V = M.named_steps['countvectorizer'].get_feature_names()\n",
    "    coef = M.named_steps['sgdclassifier'].coef_[0]\n",
    "    order = coef.argsort()\n",
    "    for w1, w2 in zip(order[-k:][::-1],order[:k]):\n",
    "        print(f'{V[w1]:20s} {coef[w1]:7.3f} | {V[w2]:20s} {coef[w2]:7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "traditional-violin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great                  5.594 | ok                    -4.987\n",
      "loved                  4.958 | average               -4.909\n",
      "perfect                4.910 | dirty                 -4.903\n",
      "excellent              4.608 | NOT:stay              -4.885\n",
      "amazing                4.420 | poor                  -4.657\n",
      "definitely             4.052 | ruined                -4.540\n",
      "wonderful              4.019 | unhelpful             -4.410\n",
      "comfortable            3.907 | not                   -4.238\n",
      "appointed              3.871 | tiny                  -4.236\n",
      "spacious               3.778 | dated                 -4.195\n",
      "minor                  3.765 | worst                 -4.173\n",
      "pleasantly             3.731 | filthy                -3.934\n",
      "spotless               3.630 | dingy                 -3.907\n",
      "NOT:beat               3.607 | terrible              -3.843\n",
      "complaint              3.527 | outdated              -3.833\n",
      "downside               3.503 | update                -3.795\n",
      "elegant                3.418 | poorly                -3.737\n",
      "quiet                  3.400 | elsewhere             -3.530\n",
      "lovely                 3.383 | NOT:cleaned           -3.522\n",
      "screen                 3.327 | smelled               -3.471\n",
      "recommend              3.293 | rude                  -3.470\n",
      "NOT:disappointed       3.236 | updating              -3.448\n",
      "NOT:eat                3.161 | stolen                -3.438\n",
      "awesome                3.113 | okay                  -3.413\n",
      "slight                 3.108 | uncomfortable         -3.395\n"
     ]
    }
   ],
   "source": [
    "print_top_feats(m1, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "qualified-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negify(tok):\n",
    "    tok._.neg = True\n",
    "    for child in tok.children:\n",
    "        negify(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alpha-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in df['doc']:\n",
    "    for t in doc:\n",
    "        t._.neg = False\n",
    "    for t in doc:        \n",
    "        if t.dep_ == 'neg':\n",
    "            t.head._.neg = True\n",
    "            for r in t.head.rights:\n",
    "                if r.dep_ in ['acomp', 'advmod', 'attr', 'dobj', 'prep', 'xcomp']:\n",
    "                    negify(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "composed-intellectual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9007"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = make_pipeline(CountVectorizer(preprocessor=identity, tokenizer=tokenize),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-5))\n",
    "m2.fit(train['doc'], train['sentiment'])\n",
    "m2.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "filled-implementation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT:hesitate           5.485 | dirty                 -5.126\n",
      "great                  5.425 | average               -4.899\n",
      "loved                  4.949 | ok                    -4.669\n",
      "perfect                4.603 | poor                  -4.539\n",
      "excellent              4.219 | ruined                -4.302\n",
      "wonderful              4.061 | dated                 -4.295\n",
      "comfortable            4.042 | disappointed          -4.217\n",
      "amazing                3.991 | unhelpful             -4.041\n",
      "pleasantly             3.815 | worst                 -4.021\n",
      "definitely             3.743 | outdated              -4.003\n",
      "downside               3.738 | filthy                -3.981\n",
      "NOT:better             3.649 | NOT:again             -3.979\n",
      "NOT:beat               3.611 | terrible              -3.874\n",
      "appointed              3.596 | not                   -3.855\n",
      "lovely                 3.578 | tiny                  -3.848\n",
      "spacious               3.554 | rude                  -3.632\n",
      "minor                  3.525 | horrible              -3.608\n",
      "elegant                3.446 | disappointing         -3.558\n",
      "spotless               3.412 | uncomfortable         -3.516\n",
      "pleased                3.406 | dingy                 -3.482\n",
      "immaculate             3.406 | update                -3.467\n",
      "complaint              3.347 | elsewhere             -3.422\n",
      "NOT:eat                3.285 | NOT:cleaned           -3.306\n",
      "fantastic              3.282 | inadequate            -3.291\n",
      "quiet                  3.214 | worn                  -3.268\n"
     ]
    }
   ],
   "source": [
    "print_top_feats(m2, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "personal-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_tokenizer(doc):\n",
    "    return [ add_neg(w.head) + '_' + add_neg(w) for w in doc \n",
    "            if w.dep_ in ['amod', 'advmod'] ] + \\\n",
    "            [ add_neg(w) for w in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "secret-ranking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['towels_clean', 'the', 'do', 'not', 'have', 'any', 'clean', 'towels', '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_tokenizer(nlp(\"The didn't have any clean towels.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fundamental-lawyer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.908"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 = make_pipeline(CountVectorizer(preprocessor=identity, tokenizer=mod_tokenizer),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-5))\n",
    "m3.fit(train['doc'], train['sentiment'])\n",
    "m3.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "center-absence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT:hesitate           5.061 | dirty                 -4.706\n",
      "loved                  4.702 | average               -4.288\n",
      "great                  4.552 | poor                  -4.049\n",
      "perfect                4.296 | ok                    -3.874\n",
      "excellent              3.840 | terrible              -3.802\n",
      "lovely                 3.500 | tiny                  -3.740\n",
      "amazing                3.471 | ruined                -3.700\n",
      "quiet                  3.430 | worst                 -3.682\n",
      "wonderful              3.245 | filthy                -3.660\n",
      "immaculate             3.099 | unhelpful             -3.576\n",
      "thing_bad              3.093 | not                   -3.541\n",
      "NOT:eat                3.093 | dated                 -3.531\n",
      "NOT:disappointed       3.088 | outdated              -3.359\n",
      "NOT:better             3.067 | horrible              -3.297\n",
      "NOT:beat               3.001 | disappointed          -3.222\n",
      "spotless               2.977 | small_so              -2.958\n",
      "spacious               2.893 | rude                  -2.942\n",
      "minor                  2.884 | thing_best            -2.927\n",
      "downside               2.875 | worn                  -2.919\n",
      "recommend              2.853 | told                  -2.901\n",
      "awesome                2.852 | nothing               -2.869\n",
      "stay_again             2.809 | uncomfortable         -2.821\n",
      "fantastic              2.750 | attempt               -2.800\n",
      "outstanding            2.709 | smell                 -2.727\n",
      "complaints             2.692 | inadequate            -2.712\n"
     ]
    }
   ],
   "source": [
    "print_top_feats(m3, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "directed-casting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def everything(doc):\n",
    "    return [ add_neg(w.head) + '_' + add_neg(w) for w in doc ] + \\\n",
    "            [ add_neg(w) for w in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "korean-specific",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['have_the',\n",
       " 'have_do',\n",
       " 'have_not',\n",
       " 'have_have',\n",
       " 'towels_any',\n",
       " 'towels_clean',\n",
       " 'have_towels',\n",
       " 'have_.',\n",
       " 'the',\n",
       " 'do',\n",
       " 'not',\n",
       " 'have',\n",
       " 'any',\n",
       " 'clean',\n",
       " 'towels',\n",
       " '.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "everything(nlp(\"The didn't have any clean towels.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "interracial-directory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9133"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4 = make_pipeline(CountVectorizer(preprocessor=identity, tokenizer=everything),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-5))\n",
    "m4.fit(train['doc'], train['sentiment'])\n",
    "m4.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aware-mexican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great                  5.480 | average               -4.770\n",
      "excellent              4.179 | ok                    -4.652\n",
      "perfect                3.821 | dirty                 -4.311\n",
      "wonderful              3.542 | not                   -4.110\n",
      "comfortable            3.281 | poor                  -3.997\n",
      "amazing                3.238 | terrible              -3.578\n",
      "lovely                 3.123 | worst                 -3.541\n",
      "quiet                  3.112 | no                    -3.392\n",
      "clean_very             2.796 | tiny                  -3.139\n",
      "definitely             2.756 | nothing               -3.048\n",
      "minor                  2.734 | rude                  -3.035\n",
      "loved                  2.681 | dated                 -2.923\n",
      "awesome                2.633 | disappointed          -2.906\n",
      "comfortable_very       2.619 | horrible              -2.894\n",
      "fantastic              2.548 | unhelpful             -2.653\n",
      "appointed              2.422 | NOT:again             -2.635\n",
      "beautiful              2.396 | bad                   -2.576\n",
      "spacious               2.343 | in_need               -2.518\n",
      "modern                 2.334 | worn                  -2.506\n",
      "comfy                  2.276 | uncomfortable         -2.495\n",
      "pleasantly             2.206 | need_of               -2.472\n",
      "NOT:better             2.185 | carpet                -2.380\n",
      "nice                   2.171 | filthy                -2.378\n",
      "stay_again             2.163 | unfriendly            -2.370\n",
      "immaculate             2.122 | told                  -2.348\n",
      "best                   2.115 | elsewhere             -2.304\n",
      "hotel_great            2.108 | barely                -2.255\n",
      "helpful                2.096 | outdated              -2.184\n",
      "outstanding            2.080 | okay                  -2.179\n",
      "free                   2.077 | poorly                -2.167\n",
      "spotless               2.050 | old                   -2.166\n",
      "everything             2.050 | small_very            -2.163\n",
      "NOT:disappointed       2.037 | hotel_average         -2.163\n",
      "5                      2.034 | NOT:stay_NOT:again    -2.152\n",
      "got_for                2.009 | disappointing         -2.151\n",
      "be_back                1.976 | awful                 -2.146\n",
      "elegant                1.974 | smell                 -2.144\n",
      "was_amazing            1.925 | expensive_very        -2.062\n",
      "immediately            1.912 | ruined                -2.061\n",
      "enjoyed                1.905 | stay_away             -2.045\n",
      "value_great            1.903 | stay_short            -2.039\n",
      "love_.                 1.864 | better                -2.026\n",
      "complaint_only         1.849 | dingy                 -2.012\n",
      "professional           1.849 | time_next             -1.986\n",
      "surprised_pleasantly   1.756 | small_so              -1.985\n",
      "stay_definitely        1.755 | dated_.               -1.976\n",
      "wine                   1.750 | stay_elsewhere        -1.947\n",
      "complaints             1.749 | tried                 -1.932\n",
      "was_perfect            1.729 | tired                 -1.927\n",
      "place_stay             1.727 | update                -1.923\n"
     ]
    }
   ],
   "source": [
    "print_top_feats(m4, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "previous-marketplace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9122"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m5 = make_pipeline(CountVectorizer(preprocessor=identity, tokenizer=everything, max_df=.93, min_df=1),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-5))\n",
    "m5.fit(train['doc'], train['sentiment'])\n",
    "m5.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-manufacturer",
   "metadata": {},
   "source": [
    "It seems that the best model to pick is the m4 moddel with the everything tokenizer because after trying out different parameters like min_df, max_df, and alpha for sgd classifier, the score doesn't get higher than 0.9133. The closest I could get to that score was when I set the min_df = 1 and max_df = 0.93, but even then the score still couldn't get higher than m4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
